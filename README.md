# Medical-Voice-Assistant-Llama2-7b
Llama2 7b



# ğŸ—£ï¸ Voice Assistant using LLaMA 2 and OpenAI Whisper

This project is a simple yet powerful voice assistant that takes voice input from the user, transcribes it using OpenAI's Whisper model, and generates a response using LLaMA 2 via the Hugging Face `transformers` library.

### ğŸ”§ Features
- ğŸ¤ Voice input recording using Python
- ğŸ§  Transcription using OpenAI Whisper
- ğŸ’¬ Natural language response generation via Meta's LLaMA 2
- ğŸ—‚ï¸ Simple and interactive design using Jupyter Notebook

### ğŸ› ï¸ Technologies Used
- Python
- OpenAI Whisper (for speech-to-text)
- Transformers (LLaMA 2)
- Torchaudio / PyTorch
- IPython display for audio interaction

### ğŸš€ Getting Started

1. Clone the repository.
2. Install dependencies from `requirements.txt`.
3. Run the Jupyter notebook `Voice_Assistant_llama2.ipynb`.

### ğŸ“ File Structure
- `Voice_Assistant_llama2.ipynb`: Main notebook for the voice assistant
- `requirements.txt`: Python package dependencies

### ğŸ’¡ Future Improvements
- Add GUI or web interface
- Real-time voice interaction
- Multi-language support

---

**Note**: This project is intended for educational and research purposes. Make sure you have access to models via Hugging Face and OpenAI as needed.
