# Medical-Voice-Assistant-Llama2-7b
Llama2 7b



# 🗣️ Voice Assistant using LLaMA 2 and OpenAI Whisper

This project is a simple yet powerful voice assistant that takes voice input from the user, transcribes it using OpenAI's Whisper model, and generates a response using LLaMA 2 via the Hugging Face `transformers` library.

### 🔧 Features
- 🎤 Voice input recording using Python
- 🧠 Transcription using OpenAI Whisper
- 💬 Natural language response generation via Meta's LLaMA 2
- 🗂️ Simple and interactive design using Jupyter Notebook

### 🛠️ Technologies Used
- Python
- OpenAI Whisper (for speech-to-text)
- Transformers (LLaMA 2)
- Torchaudio / PyTorch
- IPython display for audio interaction

### 🚀 Getting Started

1. Clone the repository.
2. Install dependencies from `requirements.txt`.
3. Run the Jupyter notebook `Voice_Assistant_llama2.ipynb`.

### 📁 File Structure
- `Voice_Assistant_llama2.ipynb`: Main notebook for the voice assistant
- `requirements.txt`: Python package dependencies

### 💡 Future Improvements
- Add GUI or web interface
- Real-time voice interaction
- Multi-language support

---

**Note**: This project is intended for educational and research purposes. Make sure you have access to models via Hugging Face and OpenAI as needed.
